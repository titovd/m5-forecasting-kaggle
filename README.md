# Предсказание спроса на товары торговой сети Walmart
* [Условия](https://github.com/titovd/m5-forecasting-kaggle/blob/master/task.pdf) задания.
* Ссылки на kaggle-соревнования: [M5-Accuracy](https://www.kaggle.com/c/m5-forecasting-accuracy), [M5-Uncertainty](https://www.kaggle.com/c/m5-forecasting-uncertainty)
* [Книга участника](https://github.com/titovd/m5-forecasting-kaggle/blob/master/m5-competitors-guide.pdf)

## Формулировка задачи на простом языке:
По данным о продажах Walmart требуется спрогнозировать ежедневные продажи товаров на ближайшие 28 дней. Данные охватывают магазины в трех штатах США (Калифорния, Техас и Висконсин) и включают уровень товара, отдел, категории продуктов и сведения о магазине. Кроме того,имеются переменные, такие как цена, акции, день недели и специальные события. 

## Формулировка задачи на математическом языке.
Набор данных, предоставленный Walmart, включает в себя единичные продажи различных продуктов, продаваемых в США. Данные организованны в виде сгруппированных временных рядов и ключает в себя единичные продажи 3049 товаров, классифицированных по 3 категориям товаров (хобби, продукты питания и домашнее хозяйство) и 7 товарным отделам, в которых вышеупомянутые категории дезагрегированы. Продукты продаются в десяти магазинах, расположенных в трех штатах (Калифорния, Техас и WI-Fi). Задача: спрогнозировать продажи товаров в различных магазинах в течение двух 28-дневных периодов времени, т.е. сделать предсказание на 28 дней для сгруппированных временных рядов. 

## Метод решения

После изучения раздела Discussion на kaggle, я решил воспользоваться градиентным бустингом. Использование нейронных сетей(в частности LSTM) затруднительно, т.к. мы их не изучали, а использвоание a ARIMA/VAR оказывается достаточно сложным из-за особенностей данных(временных рядов тысячи, их можно по-разному группировать) и, судя по тем же обсуждением на kaggle, совсем неэффективным. Я пробовал использоваться LGBM и CatBoost. 
* CatBoost: из-за особенностей работы с категориальным признаками, я ожидал более-менее хорошие результаты от модели/блендинга моделей, однако получилось не очень хорошо. CatBoost гораздо дольше учится(а данных действительно много). Блендинг же моделей не дал хорошего результата(скорее всего из-за ошибок с моей стороны)
* LGBM: Discussion-ы переполнены большим количеством примером применения именно этой библиотеки. Здесь нет такой крутой работы с категорильными признаками(их вообще я вынужден был переводить в int), но модель учится гораздо быстрее и почти из коробки показывается неплохие результаты. А вот блендинг моделей (с магическими константами с kaggle, полученными, как я понял из соображений тренда, т.е. увеличения общего объема продаж всех товаров) показывает очень даже достойный результат <0.5(но не у меня, я получил около 0.51)

